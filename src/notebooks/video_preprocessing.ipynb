{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f310fb15-0d61-4c5a-9a7e-b338f01744e8",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41d399-28e6-4d3b-9b36-40695a3ea801",
   "metadata": {},
   "source": [
    "For starters we will use ten different actors, denoted by different video id:s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962ccc4-925f-4e8f-8e6a-043960afc249",
   "metadata": {},
   "source": [
    "We will apply LOGO CV (Leave One Group Out cross-validation)\n",
    "\n",
    "We will later have to take into account variables like mode (prosody or vocalization) and intensity (1-4) in the cross validation scheme. \n",
    "\n",
    "However for the first run it will be fine to include all without taking such factors into account.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e1c469-7c68-48b9-8f56-a6d28faa6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b57b72-4799-431b-a423-5edb4d2fd5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9d71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sql_handling.execute_sql import execute_sql_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81757a24",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038e5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save figures\n",
    "output_path = '../../files/out/'\n",
    "\n",
    "# Global configuration path\n",
    "glob_conf_path = '../global_config.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1b34f1-167e-4713-8745-93895555cc61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3131c179-2417-4902-98d7-42ca9b344695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sql_handling.execute_sql import execute_sql_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd00e4-a864-4fcb-9699-896bc1f1ce07",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc30485-f73c-4325-bd1f-1e6b19db4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save figures\n",
    "output_path = '../../files/out/'\n",
    "\n",
    "# Global configuration path\n",
    "glob_conf_path = '../global_config.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b6ead1",
   "metadata": {},
   "source": [
    "# Load global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e012cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(glob_conf_path).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae55b0a",
   "metadata": {},
   "source": [
    "# Select data from DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7bb74-2690-4a8a-80d8-d9e49f3ccbae",
   "metadata": {},
   "source": [
    "We only select data that satisfies following three conditions:\n",
    "\n",
    "* Success == 1\n",
    "* Confidence rate >= 0.98\n",
    "* mix (mixed emotions) = False(0)\n",
    "\n",
    "We also only select the following six video_ids: 'A101', 'A102', 'A18', 'A200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT filename,\n",
    "video_id,\n",
    "emotion_1,\n",
    "emotion_1_id,\n",
    "AU01_r,\n",
    "AU02_r,\n",
    "AU04_r,\n",
    "AU05_r,\n",
    "AU06_r,\n",
    "AU07_r,\n",
    "AU09_r,\n",
    "AU10_r,\n",
    "AU12_r,\n",
    "AU14_r,\n",
    "AU15_r,\n",
    "AU17_r,\n",
    "AU20_r,\n",
    "AU23_r,\n",
    "AU25_r,\n",
    "AU26_r,\n",
    "AU45_r\n",
    "FROM openface\n",
    "WHERE success = 1 AND confidence >= 0.98 AND mix = 0;\"\"\"\n",
    "\n",
    "df, read_duration = execute_sql_pandas(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd049d4b-33be-41d0-af21-6325eb79764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"query executed in: {} seconds\".format(read_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc64424-5221-4447-b2b8-1d02daf70327",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78668baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of instances: {}\".format(len(df)))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Number of Instances per File (before data cleaning)\")\n",
    "file_val_counts_original = df[\"filename\"].value_counts()\n",
    "print(file_val_counts_original)\n",
    "print()\n",
    "\n",
    "\n",
    "x = file_val_counts_original.values\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(x, rug=True, norm_hist=True,\n",
    "             rug_kws={'color': blue_shades[0],'alpha':1},\n",
    "             kde_kws={'color': blue_shades[0],'alpha':1},\n",
    "             hist_kws={'color': blue_shades[1], 'alpha':0.6}\n",
    "            )\n",
    "plt.xlabel('Number of Instances')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(False,axis='x')\n",
    "plt.savefig(os.path.join(output_path,'charts','report_distribution_before_cleaning.svg'), bbox_inches = 'tight')\n",
    "plt.title('Density Plot with Rug Plot (before data cleaning)')\n",
    "plt.savefig(os.path.join(output_path,'charts','distribution_before_cleaning.svg'), bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Number of Instances per Video id (before data cleaning)\")\n",
    "video_val_counts_original = df[\"video_id\"].value_counts()\n",
    "print(video_val_counts_original)\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(video_val_counts_original.index, video_val_counts_original.values, saturation=sns_saturation, color=blue_rgb)\n",
    "plt.title(\"Number of instances per video before data cleaning\")\n",
    "plt.xlabel('video ID')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Number of Instances per Emotion (before data cleaning)\")\n",
    "emotion_val_counts_original = df[\"emotion_1\"].value_counts()\n",
    "print(emotion_val_counts_original)\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(emotion_val_counts_original.index, emotion_val_counts_original.values, saturation=sns_saturation, color=blue_rgb)\n",
    "plt.title(\"Number of instances per emotion before data cleaning\")\n",
    "plt.xlabel('Emotion ID')\n",
    "plt.ylabel('Number of Instances')\n",
    "#plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0660db-466a-4a40-8499-50815b8c506d",
   "metadata": {},
   "source": [
    "Lets see how many files we have per video id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24cc9a4-bd46-49e7-8186-7c2e738466fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Instances per video id for every filename\")\n",
    "video_val_counts_original = df[['video_id','filename']].groupby([\"video_id\"]).filename.nunique().reset_index()\n",
    "print(video_val_counts_original)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e77d389-f006-4ccf-af76-31ff02f35353",
   "metadata": {},
   "source": [
    "# From time series data to average features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e105f-c467-44cf-9e28-cea2b47bc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def my_find_peaks(x):\n",
    "    \"\"\"\n",
    "    This function takes a 1-D array and finds all local maxima by simple comparison of neighboring values. \n",
    "    Optionally, a subset of these peaks can be selected by specifying conditions for a peakâ€™s properties.\n",
    "    \"\"\"\n",
    "    th = x.mean()\n",
    "    val = x.values\n",
    "    peaks, _ = find_peaks(val, height=th)\n",
    "    return len(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7dbf70-da56-4cca-ae09-a508027fd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df.drop(columns=[\"video_id\", \"emotion_1\", \"emotion_1_id\"])\n",
    "\n",
    "# Compute statistical measures \n",
    "df_tmp = df_tmp.groupby(['filename']).agg(['mean',                                    # Arithmetic mean\n",
    "                                          lambda x: scipy.stats.variation(x),        # Coefficient of variation\n",
    "                                          lambda x: np.percentile(x, q=20),          # 20th percentile, i.e. below this value 20% of the observations will be found\n",
    "                                          lambda x: np.percentile(x, q=50),          # 50th percentile, i.e. below this value 50% of the observations will be found\n",
    "                                          lambda x: np.percentile(x, q=80),          # 80th percentile, i.e. below this value 80% of the observations will be found\n",
    "                                          lambda x: scipy.stats.iqr(x, rng=(20,80)), # IQR(60%) = 80th percentile - 20th percentile\n",
    "                                          lambda x: my_find_peaks(x),                # Number of peaks above the adaptive threshold\n",
    "                                          ]).reset_index().sort_values(by=['filename'], ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "df_tmp.rename(columns={'<lambda_0>': 'stddevNorm',\n",
    "                       '<lambda_1>': 'percentile20.0',\n",
    "                       '<lambda_2>': 'percentile50.0',\n",
    "                       '<lambda_3>': 'percentile80.0',\n",
    "                       '<lambda_4>': 'iqr60_80-20',\n",
    "                       '<lambda_5>': 'numPeaks',\n",
    "                      }, level=1,inplace=True)\n",
    "\n",
    "# Impute NaN values\n",
    "# There might be some NaN values in the dataframe coming from the coefficient of variation (std(x)/mean(x) when mean(x)=0) \n",
    "df_tmp.fillna(0, inplace=True)\n",
    "\n",
    "# Collapse hierarchical index in columns\n",
    "df_tmp.columns = ['_'.join(col).strip('_') for col in df_tmp.columns.values]\n",
    "\n",
    "# check for null values\n",
    "df_tmp.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2c98c-8af9-4302-90b2-b2233bb46a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f45e9-36d3-4803-9789-ef22b79ddb30",
   "metadata": {},
   "source": [
    "# Normalize training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544d6fec-842f-4ce0-b311-fbae9bbc6786",
   "metadata": {},
   "source": [
    "Merge on filename index... Merge with metadata afterwards..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e92b58-7e50-4c32-99a1-615ace64a2b3",
   "metadata": {},
   "source": [
    "A way to normalize the input features/variables is the Min-Max scaler. By doing so, all features will be transformed into the range [0,1] meaning that the minimum and maximum value of a feature/variable is going to be 0 and 1, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aee42b2-7cf8-4000-91cf-939803690570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# create a separate dataframe to keep track of index\n",
    "df_filename = df_tmp[[\"filename\"]]\n",
    "\n",
    "# get only features\n",
    "X = df_tmp.drop(columns=['filename'])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Fit and transform features\n",
    "X_scaled = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Create a dataframe from normalized features\n",
    "X_scaled_df = pd.DataFrame(data=X_scaled, columns=X.columns.to_list())\n",
    "\n",
    "# join back on index with filename dataframe\n",
    "X_scaled_df = df_filename.join(X_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f6438-4183-46b3-990b-4846f5ea790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da26aa-7deb-415e-903d-1f3ce571cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the metadata from original dataframe\n",
    "df_metadata = df[[\"filename\", \"video_id\", \"emotion_1_id\"]]\n",
    "\n",
    "# drop all duplicate rows, will collapse dataframe to unique filenames\n",
    "df_metadata = df_metadata.drop_duplicates()\n",
    "\n",
    "# merge metadata with temporary dataframe\n",
    "train_scaled_df = pd.merge(X_scaled_df, df_metadata, on=\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd50ea3d-1d51-49e5-a5cd-22dcd430a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1ffdc-6378-4ee8-ab5d-7bfb086b3298",
   "metadata": {},
   "source": [
    "# Create groups for LOGO CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6a494-899c-4981-98af-1bd5d6e45cae",
   "metadata": {},
   "source": [
    "We will apply LOGO CV (Leave One Group Out cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1394a706-0078-47c3-95b5-2617e365cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled_df.video_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438e5e3-c419-4229-848e-6199f3533dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evens(size):\n",
    "    ret = []\n",
    "    for n in range(size):\n",
    "        if n % 2 == 0:\n",
    "            ret.append(n)\n",
    "    return ret\n",
    "\n",
    "def get_odds(size):\n",
    "    ret = []\n",
    "    for n in range(size):\n",
    "        if n % 2 == 1:\n",
    "            ret.append(n)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3374623-4032-4f4d-9c43-ffdf76addace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "video_ids = train_scaled_df.video_id.unique()\n",
    "\n",
    "# Find random pairs of video_ids\n",
    "random.seed(seed)\n",
    "\n",
    "# a list of even numbers\n",
    "video_ids_1 = get_evens(len(video_ids))\n",
    "\n",
    "# a list of odd numbers\n",
    "video_ids_2 = get_odds(len(video_ids))\n",
    "\n",
    "# shuffle the odd numbers\n",
    "video_ids_2_shuffled = random.sample(video_ids_2, len(video_ids_2))\n",
    "\n",
    "# assign groups for video ids by using odd and even numbers respectively\n",
    "groups = {}\n",
    "for i, video_id in enumerate(video_ids_1):\n",
    "    groups[video_ids[video_id]] = i\n",
    "    \n",
    "for i, video_id in enumerate(video_ids_2_shuffled):\n",
    "    groups[video_ids[video_id]] = i\n",
    "    \n",
    "print(groups)\n",
    "\n",
    "# Create a copy\n",
    "train_scaled_groups_df = train_scaled_df.copy()\n",
    "\n",
    "# Insert group column\n",
    "train_scaled_groups_df['group'] = train_scaled_groups_df['video_id'].map(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b63b0-cecf-4c9a-a3ef-2872ca6ff99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled_groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a99bbb-ad01-4844-84d3-79dcba4bb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(output_path, \"video\", 'video_data_intensity_train.csv')\n",
    "train_scaled_groups_df.to_csv(save_path, index=None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
