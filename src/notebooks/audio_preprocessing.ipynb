{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac33ca11-bae4-4996-87f1-e7cf2c1ffea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5867ce8-1017-49ee-a5e2-8c390763f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0d6b0-4c35-442f-91f6-751449119d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sql_handling.execute_sql import execute_sql_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e532eeb-1d34-4929-b4ab-5d807f337c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# path to save figures\n",
    "output_path = os.getenv(\"AUDIO_OUT\")\n",
    "\n",
    "# Global configuration path\n",
    "glob_conf_path = '../global_config.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2df58a-3487-470c-8993-32c6e908c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(glob_conf_path).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca731aa-ab39-455f-a21c-2908f4231f5f",
   "metadata": {},
   "source": [
    "# Select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94aa2b-fa2a-4464-ae4c-8379ffdfa6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT *\n",
    "FROM opensmile_functionals\n",
    "WHERE mix = 0\n",
    "AND video_id IN ('A101', 'A102', 'A18', 'A200')\"\"\"\n",
    "df, read_duration = execute_sql_pandas(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50edef85-e307-4780-8e31-679383551805",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"query executed in: {} seconds\".format(read_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994fab00-d8ff-489f-87b5-9ede27b56cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408bc0f-7aa5-4692-a3a0-b7884bfe8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"file\", \"start\", \"end\", \"mix\", \"emotion_2\", \"emotion_2_id\",  \n",
    "                      \"proportions\", \"mode\", \"intensity_level\",\n",
    "                      \"version\", \"situation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474864a-188b-4459-af14-8d5539daf35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6381ba-2600-4926-97e7-c4f1301b5080",
   "metadata": {},
   "source": [
    "# Data inspection before data cleaning\n",
    "In this section we will inspect the dataset. For this porpuse, we will focus on the number of files per emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda976e-fb65-435e-afc1-9fa23dec43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Files per emotion before data cleaning')\n",
    "files_per_emotion_count_original = df[['emotion_1','filename']].groupby(['emotion_1']).filename.nunique()\n",
    "print('Total number of files: {}'.format(files_per_emotion_count_original.sum()))\n",
    "print(files_per_emotion_count_original)\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(files_per_emotion_count_original.index, files_per_emotion_count_original.values, saturation=sns_saturation, color=blue_rgb)\n",
    "plt.title('Files per emotion before data cleaning (eGeMAPS)')\n",
    "plt.xlabel('Emotion ID')\n",
    "plt.ylabel('Number of Files')\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed40f68-3e49-4f87-a00f-0043266b79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec477a9-cc54-44b1-a61c-524dad4b48e0",
   "metadata": {},
   "source": [
    "# Normalize training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab82949-91f0-4ff0-ada0-e23a68a5539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# eGeMAPS\n",
    "X = df.drop(columns=['emotion_1','emotion_1_id','filename','video_id'])          # Get features from training set\n",
    "min_max_scaler_egemaps = preprocessing.MinMaxScaler()                     # eGeMAPS min max scaler\n",
    "X_scaled = min_max_scaler_egemaps.fit_transform(X)                        # Fit and transform features\n",
    "X_scaled_df = pd.DataFrame(data=X_scaled, columns=X.columns.to_list())    # Create a dataframe from normalized features\n",
    "metadata_df = df[['emotion_1_id','filename','video_id']]\n",
    "train_scaled_df = pd.concat([X_scaled_df,metadata_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc3a01-e9a6-479e-a1b1-13f00400b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_egemaps_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809413c-0d48-4ae3-8898-e911d5a9436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled_df.video_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c1591-1e8d-4d94-ab87-62c525f6b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evens(size):\n",
    "    ret = []\n",
    "    for n in range(size):\n",
    "        if n % 2 == 0:\n",
    "            ret.append(n)\n",
    "    return ret\n",
    "\n",
    "def get_odds(size):\n",
    "    ret = []\n",
    "    for n in range(size):\n",
    "        if n % 2 == 1:\n",
    "            ret.append(n)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80de18-d511-4f25-89f0-92bfbdac2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "video_ids = train_scaled_df.video_id.unique()\n",
    "\n",
    "# Find random pairs of video_ids\n",
    "random.seed(seed)\n",
    "\n",
    "# a list of even numbers\n",
    "video_ids_1 = get_evens(len(video_ids))\n",
    "\n",
    "# a list of odd numbers\n",
    "video_ids_2 = get_odds(len(video_ids))\n",
    "\n",
    "# shuffle the odd numbers\n",
    "video_ids_2_shuffled = random.sample(video_ids_2, len(video_ids_2))\n",
    "\n",
    "# assign groups for video ids by using odd and even numbers respectively\n",
    "groups = {}\n",
    "for i, video_id in enumerate(video_ids_1):\n",
    "    groups[video_ids[video_id]] = i\n",
    "    \n",
    "for i, video_id in enumerate(video_ids_2_shuffled):\n",
    "    groups[video_ids[video_id]] = i\n",
    "    \n",
    "print(groups)\n",
    "\n",
    "# Create a copy\n",
    "train_scaled_groups_df = train_scaled_df.copy()\n",
    "\n",
    "# Insert group column\n",
    "train_scaled_groups_df['group'] = train_scaled_groups_df['video_id'].map(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4bce4-e181-415d-a111-3145d8df3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled_groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89ce1c-b488-4eb8-828c-47e9293143d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(output_path, 'audio_data_egemaps_train.csv')\n",
    "train_scaled_groups_df.to_csv(save_path, index=None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
