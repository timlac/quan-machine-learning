{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5dc38057-5376-40d7-a1e6-5612c50226f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randrange\n",
    "import pandas as pd\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbaed0cd-52b5-468c-9186-60b68ecfb75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/emotional-recognition/notebooks/low_level/supervised_learning/audio'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e174b6a-1c17-46de-a664-9a7376fec267",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/root/emotional-recognition/notebooks/low_level/supervised_learning/audio/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28e390b-39e8-4407-99d5-14db613db08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/emotional-recognition/notebooks/low_level/supervised_learning/audio'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a2a11-def5-4a21-b440-4b9665f92c49",
   "metadata": {},
   "source": [
    "# GEMEP with egemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eda4d79-454a-47a0-847f-62320a76a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3fs.core import S3FileSystem\n",
    "s3 = S3FileSystem()\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket='files-and-examples-01'\n",
    "file = 'datasets/gemep/gemep_audio_time_series.npz'\n",
    "\n",
    "path = s3.open('s3://{}/{}'.format(bucket, file))\n",
    "\n",
    "f = np.load(path, 'r')\n",
    "x = f['x']\n",
    "y = f['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b0af05-485f-41e9-85b9-f8d7858b8c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 842, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855cfc33-f763-4751-8f39-eb73b1b61d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7fca12-f291-411e-bfc3-226341c994b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02b9bc39-84e1-48ab-ac61-8f52a481b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "156fa50c-824b-4b04-8ff0-a13946448195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_3 (Masking)          (None, 842, 25)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 842, 512)          1101824   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 842, 256)          787456    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 215552)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               55181568  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 18)                2322      \n",
      "=================================================================\n",
      "Total params: 57,106,066\n",
      "Trainable params: 57,106,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_len = x.shape[1]\n",
    "n_cols = x.shape[2]\n",
    "output_dim = len(np.unique(y))\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Masking(mask_value = -1000, input_shape=(seq_len, n_cols)),\n",
    "        layers.LSTM(units=512,\n",
    "                   return_sequences=True,\n",
    "                   input_shape=(seq_len, n_cols)),\n",
    "        layers.LSTM(units=256,\n",
    "                   return_sequences=True,),        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation=\"sigmoid\"),\n",
    "        layers.Dense(128, activation=\"sigmoid\"),\n",
    "        layers.Dense(output_dim, activation=\"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4285378d-2984-4868-ab9e-2f34bddd1e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 9s 435ms/step - loss: 2.9143 - accuracy: 0.0862 - val_loss: 2.8277 - val_accuracy: 0.1217\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 2.7844 - accuracy: 0.1020 - val_loss: 2.7664 - val_accuracy: 0.1349\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 2.7054 - accuracy: 0.1542 - val_loss: 2.7171 - val_accuracy: 0.1561\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 2.6435 - accuracy: 0.1837 - val_loss: 2.6849 - val_accuracy: 0.1561\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 2.5743 - accuracy: 0.2109 - val_loss: 2.6474 - val_accuracy: 0.1667\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 2s 189ms/step - loss: 2.5070 - accuracy: 0.2381 - val_loss: 2.6263 - val_accuracy: 0.1984\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 2.4289 - accuracy: 0.3118 - val_loss: 2.6038 - val_accuracy: 0.2116\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 2s 190ms/step - loss: 2.3352 - accuracy: 0.3730 - val_loss: 2.6001 - val_accuracy: 0.1852\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 2.2385 - accuracy: 0.4467 - val_loss: 2.5854 - val_accuracy: 0.2090\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 2.1313 - accuracy: 0.4943 - val_loss: 2.5646 - val_accuracy: 0.2143\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 2.0337 - accuracy: 0.5476 - val_loss: 2.5674 - val_accuracy: 0.2037\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 1.9172 - accuracy: 0.6383 - val_loss: 2.5605 - val_accuracy: 0.2143\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 2s 188ms/step - loss: 1.8105 - accuracy: 0.7177 - val_loss: 2.5456 - val_accuracy: 0.2222\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 1.7099 - accuracy: 0.7426 - val_loss: 2.5550 - val_accuracy: 0.2169\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 1.6022 - accuracy: 0.7959 - val_loss: 2.5605 - val_accuracy: 0.2116\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 1.4967 - accuracy: 0.8379 - val_loss: 2.5616 - val_accuracy: 0.1958\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 2s 189ms/step - loss: 1.3997 - accuracy: 0.8583 - val_loss: 2.5718 - val_accuracy: 0.2063\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 2s 189ms/step - loss: 1.3094 - accuracy: 0.8821 - val_loss: 2.5680 - val_accuracy: 0.2011\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 2s 187ms/step - loss: 1.2254 - accuracy: 0.9093 - val_loss: 2.5707 - val_accuracy: 0.2063\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 1.1421 - accuracy: 0.9320 - val_loss: 2.5709 - val_accuracy: 0.2116\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 1.0708 - accuracy: 0.9433 - val_loss: 2.5887 - val_accuracy: 0.2037\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 2s 188ms/step - loss: 1.0033 - accuracy: 0.9569 - val_loss: 2.5885 - val_accuracy: 0.2169\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 0.9414 - accuracy: 0.9637 - val_loss: 2.5854 - val_accuracy: 0.2169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa833b69850>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=100, epochs=200, validation_data=(X_test, y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1623b467-7a14-43d9-a4d1-0c29fbdbecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cc37938-fcf0-49ef-8ccd-98f98280a66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 18)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c16d27a-8b43-48bb-93b0-49c26a479db4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22812739, 0.75123197, 0.26695713, 0.71414995, 0.30736938,\n",
       "       0.80332845, 0.6166555 , 0.16934572, 0.3400268 , 0.5842783 ,\n",
       "       0.27325326, 0.81106746, 0.3604107 , 0.9201705 , 0.30282494,\n",
       "       0.492423  , 0.41047612, 0.31283128], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fe4fa2-35ac-4b4a-8044-70dcb1722343",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a413cedb-b6c5-4bb0-972c-e729814cfbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = tf.keras.layers.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b985313-e0b9-46dc-a579-4e7fb89204e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "unique_labels = np.unique(y)\n",
    "\n",
    "ret = np.zeros((output_dim, output_dim))\n",
    "\n",
    "for idx, pred in enumerate(y_pred):\n",
    "    y_true = y_test[idx]\n",
    "    ret[y_true] += pred\n",
    "    \n",
    "softmax_ret = layer(ret).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8619a9-223a-4e17-9889-2e59c24421e3",
   "metadata": {},
   "source": [
    "# Preicion and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c22681a5-603e-49a1-8192-234052a201a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemep_emotion_abr_to_emotion = {'adm': 'admiration',\n",
    "                                'amu': 'amusement',\n",
    "                                'att': 'tenderness',\n",
    "                                'col': 'anger',\n",
    "                                'deg': 'disgust',\n",
    "                                'des': 'despair',\n",
    "                                'fie': 'pride',\n",
    "                                'hon': 'shame',\n",
    "                                'inq': 'anxiety',\n",
    "                                'int': 'interest',\n",
    "                                'irr': 'irritation',\n",
    "                                'joi': 'joy',\n",
    "                                'mep': 'contempt',\n",
    "                                'peu': 'panic',\n",
    "                                'pla': 'pleasure',\n",
    "                                'sou': 'relief',\n",
    "                                'sur': 'surprise',\n",
    "                                'tri': 'sadness'\n",
    "                                }\n",
    "\n",
    "labels = list(gemep_emotion_abr_to_emotion.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "03a73ac4-2e47-49d5-bfef-415331660184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admiration',\n",
       " 'amusement',\n",
       " 'tenderness',\n",
       " 'anger',\n",
       " 'disgust',\n",
       " 'despair',\n",
       " 'pride',\n",
       " 'shame',\n",
       " 'anxiety',\n",
       " 'interest',\n",
       " 'irritation',\n",
       " 'joy',\n",
       " 'contempt',\n",
       " 'panic',\n",
       " 'pleasure',\n",
       " 'relief',\n",
       " 'surprise',\n",
       " 'sadness']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1cf50525-6366-4f65-b001-0a0e1634102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_y_pred = layer(y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c71da45e-751e-4d32-86ce-12b70695b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_categorical = np.argmax(softmax_y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19cb4411-494d-46f9-a53f-37f2a083e91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  6,  8,  9, 10, 11, 13, 14, 15, 17])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "281e22ee-73a3-41ed-9657-df96a7bdbeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  admiration      0.000     0.000     0.000         8\n",
      "   amusement      0.269     0.241     0.255        29\n",
      "  tenderness      0.000     0.000     0.000         9\n",
      "       anger      0.217     0.152     0.179        33\n",
      "     disgust      0.000     0.000     0.000        10\n",
      "     despair      0.156     0.238     0.189        21\n",
      "       pride      0.163     0.258     0.200        31\n",
      "       shame      0.000     0.000     0.000         8\n",
      "     anxiety      0.194     0.286     0.231        21\n",
      "    interest      0.057     0.069     0.062        29\n",
      "  irritation      0.211     0.182     0.195        22\n",
      "         joy      0.333     0.259     0.292        27\n",
      "    contempt      0.000     0.000     0.000         8\n",
      "       panic      0.395     0.484     0.435        31\n",
      "    pleasure      0.333     0.229     0.271        35\n",
      "      relief      0.192     0.185     0.189        27\n",
      "    surprise      0.000     0.000     0.000         7\n",
      "     sadness      0.185     0.455     0.263        22\n",
      "\n",
      "    accuracy                          0.217       378\n",
      "   macro avg      0.150     0.169     0.153       378\n",
      "weighted avg      0.201     0.217     0.201       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_categorical, target_names=labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "391d0d0d-e8c7-42a7-833b-624af4f67320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1687213608978533\n",
      "0.21693121693121692\n",
      "0.21693121693121692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(recall_score(y_test, y_pred_categorical, average='macro'))\n",
    "print(recall_score(y_test, y_pred_categorical, average='micro'))\n",
    "print(recall_score(y_test, y_pred_categorical, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25850495-883c-4ded-b002-d13a30d61177",
   "metadata": {},
   "source": [
    "# GEMEP with Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a332df-77aa-48b8-a7ce-dcab41058e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3fs.core import S3FileSystem\n",
    "s3 = S3FileSystem()\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket='files-and-examples-01'\n",
    "file = 'datasets/gemep/gemep_compare_audio_time_series.npz'\n",
    "\n",
    "path = s3.open('s3://{}/{}'.format(bucket, file))\n",
    "\n",
    "f = np.load(path, 'r')\n",
    "x = f['x']\n",
    "y = f['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a5bd337-e8a6-4630-a690-85416bd63309",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66ca8aa9-41a0-47cd-95a9-d25dc57be1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_5 (Masking)          (None, 842, 65)           0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 842, 512)          1183744   \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 842, 256)          787456    \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 215552)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               55181568  \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 18)                2322      \n",
      "=================================================================\n",
      "Total params: 57,187,986\n",
      "Trainable params: 57,187,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_len = x.shape[1]\n",
    "n_cols = x.shape[2]\n",
    "output_dim = len(np.unique(y))\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Masking(mask_value = -1000, input_shape=(seq_len, n_cols)),\n",
    "        layers.LSTM(units=512,\n",
    "                   return_sequences=True,\n",
    "                   input_shape=(seq_len, n_cols)),\n",
    "        layers.LSTM(units=256,\n",
    "                   return_sequences=True,),        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation=\"sigmoid\"),\n",
    "        layers.Dense(128, activation=\"sigmoid\"),\n",
    "        layers.Dense(output_dim, activation=\"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ce3d8b5-fb10-4c03-91b2-76c56933f41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 10s 458ms/step - loss: 2.9154 - accuracy: 0.0771 - val_loss: 2.8092 - val_accuracy: 0.1032\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 2s 195ms/step - loss: 2.8002 - accuracy: 0.0975 - val_loss: 2.7934 - val_accuracy: 0.1190\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 2.7708 - accuracy: 0.1168 - val_loss: 2.7721 - val_accuracy: 0.1243\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 2s 194ms/step - loss: 2.7385 - accuracy: 0.1429 - val_loss: 2.7535 - val_accuracy: 0.1190\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 2.7030 - accuracy: 0.1587 - val_loss: 2.7361 - val_accuracy: 0.1349\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 2.6675 - accuracy: 0.1803 - val_loss: 2.7116 - val_accuracy: 0.1376\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 2.6230 - accuracy: 0.2063 - val_loss: 2.6906 - val_accuracy: 0.1455\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 2.5849 - accuracy: 0.2132 - val_loss: 2.6593 - val_accuracy: 0.1614\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 2.5403 - accuracy: 0.2494 - val_loss: 2.6354 - val_accuracy: 0.1878\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 2.5073 - accuracy: 0.2721 - val_loss: 2.6089 - val_accuracy: 0.1984\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 2.4638 - accuracy: 0.2902 - val_loss: 2.6022 - val_accuracy: 0.1931\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 2.4174 - accuracy: 0.3299 - val_loss: 2.6533 - val_accuracy: 0.1772\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 2.4392 - accuracy: 0.2948 - val_loss: 2.5988 - val_accuracy: 0.1958\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 2.3559 - accuracy: 0.3651 - val_loss: 2.5635 - val_accuracy: 0.1984\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 2.3177 - accuracy: 0.3673 - val_loss: 2.5807 - val_accuracy: 0.1905\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 2.2660 - accuracy: 0.3991 - val_loss: 2.5519 - val_accuracy: 0.2037\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 2.2233 - accuracy: 0.4240 - val_loss: 2.5560 - val_accuracy: 0.1852\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 2.1806 - accuracy: 0.4433 - val_loss: 2.5698 - val_accuracy: 0.1958\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 2s 194ms/step - loss: 2.1562 - accuracy: 0.4399 - val_loss: 2.5409 - val_accuracy: 0.2090\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 2.1076 - accuracy: 0.4762 - val_loss: 2.5278 - val_accuracy: 0.1905\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 2.0734 - accuracy: 0.4717 - val_loss: 2.5241 - val_accuracy: 0.2063\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 2.0229 - accuracy: 0.5113 - val_loss: 2.5163 - val_accuracy: 0.2090\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 1.9888 - accuracy: 0.5147 - val_loss: 2.4981 - val_accuracy: 0.2169\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.9491 - accuracy: 0.5533 - val_loss: 2.4915 - val_accuracy: 0.2143\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 1.9147 - accuracy: 0.5635 - val_loss: 2.5006 - val_accuracy: 0.2169\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 1.8607 - accuracy: 0.5862 - val_loss: 2.4673 - val_accuracy: 0.2143\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 1.8258 - accuracy: 0.5952 - val_loss: 2.4906 - val_accuracy: 0.2011\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 1.7837 - accuracy: 0.6043 - val_loss: 2.4673 - val_accuracy: 0.2249\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.7403 - accuracy: 0.6372 - val_loss: 2.4763 - val_accuracy: 0.2302\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 1.6936 - accuracy: 0.6565 - val_loss: 2.4646 - val_accuracy: 0.2328\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 1.6426 - accuracy: 0.6757 - val_loss: 2.4462 - val_accuracy: 0.2063\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 1.5978 - accuracy: 0.6984 - val_loss: 2.4516 - val_accuracy: 0.2011\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 1.5648 - accuracy: 0.7041 - val_loss: 2.4549 - val_accuracy: 0.2143\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.5428 - accuracy: 0.6984 - val_loss: 2.4395 - val_accuracy: 0.2143\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.5431 - accuracy: 0.7052 - val_loss: 2.4433 - val_accuracy: 0.2196\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.4976 - accuracy: 0.7063 - val_loss: 2.4166 - val_accuracy: 0.2381\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 1.4421 - accuracy: 0.7381 - val_loss: 2.4436 - val_accuracy: 0.2169\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 1.3974 - accuracy: 0.7540 - val_loss: 2.4436 - val_accuracy: 0.2196\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.3755 - accuracy: 0.7494 - val_loss: 2.4441 - val_accuracy: 0.2302\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 1.3613 - accuracy: 0.7653 - val_loss: 2.4440 - val_accuracy: 0.2222\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 1.3371 - accuracy: 0.7744 - val_loss: 2.4323 - val_accuracy: 0.2169\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 1.2838 - accuracy: 0.7959 - val_loss: 2.4381 - val_accuracy: 0.2169\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 1.2650 - accuracy: 0.7914 - val_loss: 2.4730 - val_accuracy: 0.2090\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 1.2592 - accuracy: 0.7812 - val_loss: 2.4554 - val_accuracy: 0.2037\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 1.2039 - accuracy: 0.8084 - val_loss: 2.4342 - val_accuracy: 0.2249\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 1.2086 - accuracy: 0.7925 - val_loss: 2.4606 - val_accuracy: 0.2275\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 1.1692 - accuracy: 0.8152 - val_loss: 2.4524 - val_accuracy: 0.2196\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 1.1451 - accuracy: 0.8118 - val_loss: 2.4295 - val_accuracy: 0.2407\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 1.1094 - accuracy: 0.8333 - val_loss: 2.4583 - val_accuracy: 0.2196\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 1.0778 - accuracy: 0.8481 - val_loss: 2.4658 - val_accuracy: 0.2354\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 1.0470 - accuracy: 0.8447 - val_loss: 2.4425 - val_accuracy: 0.2381\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 1.0190 - accuracy: 0.8617 - val_loss: 2.4316 - val_accuracy: 0.2302\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.9939 - accuracy: 0.8685 - val_loss: 2.4482 - val_accuracy: 0.2196\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.9492 - accuracy: 0.8844 - val_loss: 2.4536 - val_accuracy: 0.2222\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.9233 - accuracy: 0.8946 - val_loss: 2.4524 - val_accuracy: 0.2222\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 0.8920 - accuracy: 0.9025 - val_loss: 2.4732 - val_accuracy: 0.2196\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.8742 - accuracy: 0.8980 - val_loss: 2.4728 - val_accuracy: 0.2063\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.8869 - accuracy: 0.8821 - val_loss: 2.4765 - val_accuracy: 0.2487\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.8471 - accuracy: 0.9127 - val_loss: 2.4981 - val_accuracy: 0.1905\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.8201 - accuracy: 0.9116 - val_loss: 2.4922 - val_accuracy: 0.2143\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.7896 - accuracy: 0.9184 - val_loss: 2.4804 - val_accuracy: 0.2169\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.8100 - accuracy: 0.9093 - val_loss: 2.4967 - val_accuracy: 0.2090\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 0.7829 - accuracy: 0.9206 - val_loss: 2.4951 - val_accuracy: 0.2249\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.7550 - accuracy: 0.9320 - val_loss: 2.4939 - val_accuracy: 0.2196\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.7122 - accuracy: 0.9365 - val_loss: 2.4875 - val_accuracy: 0.2169\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.7401 - accuracy: 0.9274 - val_loss: 2.5100 - val_accuracy: 0.2169\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.7590 - accuracy: 0.9138 - val_loss: 2.5346 - val_accuracy: 0.2116\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.7286 - accuracy: 0.9331 - val_loss: 2.5296 - val_accuracy: 0.2249\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.7042 - accuracy: 0.9218 - val_loss: 2.5338 - val_accuracy: 0.2196\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.6635 - accuracy: 0.9467 - val_loss: 2.5283 - val_accuracy: 0.2090\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.6272 - accuracy: 0.9535 - val_loss: 2.4922 - val_accuracy: 0.2196\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 0.5929 - accuracy: 0.9728 - val_loss: 2.4991 - val_accuracy: 0.2302\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.5782 - accuracy: 0.9637 - val_loss: 2.5327 - val_accuracy: 0.2275\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.5685 - accuracy: 0.9580 - val_loss: 2.5082 - val_accuracy: 0.2222\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.5593 - accuracy: 0.9649 - val_loss: 2.5316 - val_accuracy: 0.2143\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.5388 - accuracy: 0.9773 - val_loss: 2.5293 - val_accuracy: 0.2063\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.5200 - accuracy: 0.9739 - val_loss: 2.5353 - val_accuracy: 0.2037\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.5010 - accuracy: 0.9762 - val_loss: 2.5250 - val_accuracy: 0.2090\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.4809 - accuracy: 0.9864 - val_loss: 2.5258 - val_accuracy: 0.2116\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.4637 - accuracy: 0.9819 - val_loss: 2.5186 - val_accuracy: 0.2302\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.4470 - accuracy: 0.9864 - val_loss: 2.5399 - val_accuracy: 0.2063\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.4251 - accuracy: 0.9909 - val_loss: 2.5340 - val_accuracy: 0.2116\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.4080 - accuracy: 0.9921 - val_loss: 2.5206 - val_accuracy: 0.2116\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.3925 - accuracy: 0.9921 - val_loss: 2.5444 - val_accuracy: 0.2116\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.3814 - accuracy: 0.9943 - val_loss: 2.5429 - val_accuracy: 0.2143\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.3709 - accuracy: 0.9932 - val_loss: 2.5407 - val_accuracy: 0.2275\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.3643 - accuracy: 0.9921 - val_loss: 2.5576 - val_accuracy: 0.2116\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.3545 - accuracy: 0.9921 - val_loss: 2.5693 - val_accuracy: 0.2090\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.3413 - accuracy: 0.9955 - val_loss: 2.5553 - val_accuracy: 0.2275\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.3335 - accuracy: 0.9943 - val_loss: 2.5639 - val_accuracy: 0.2328\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.3271 - accuracy: 0.9989 - val_loss: 2.5531 - val_accuracy: 0.2116\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.3107 - accuracy: 1.0000 - val_loss: 2.5770 - val_accuracy: 0.2169\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.3047 - accuracy: 0.9966 - val_loss: 2.5771 - val_accuracy: 0.2116\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.2896 - accuracy: 0.9989 - val_loss: 2.5654 - val_accuracy: 0.2302\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.2798 - accuracy: 0.9989 - val_loss: 2.5697 - val_accuracy: 0.2116\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.2709 - accuracy: 0.9989 - val_loss: 2.5886 - val_accuracy: 0.2143\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 0.2632 - accuracy: 1.0000 - val_loss: 2.5792 - val_accuracy: 0.2249\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.2536 - accuracy: 1.0000 - val_loss: 2.5869 - val_accuracy: 0.2222\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.2486 - accuracy: 0.9989 - val_loss: 2.5849 - val_accuracy: 0.2275\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.2445 - accuracy: 1.0000 - val_loss: 2.5838 - val_accuracy: 0.2196\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.2462 - accuracy: 0.9966 - val_loss: 2.5962 - val_accuracy: 0.2143\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.2418 - accuracy: 1.0000 - val_loss: 2.6033 - val_accuracy: 0.2143\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.2411 - accuracy: 1.0000 - val_loss: 2.6429 - val_accuracy: 0.2090\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.2525 - accuracy: 0.9955 - val_loss: 2.5948 - val_accuracy: 0.2116\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.2834 - accuracy: 0.9887 - val_loss: 2.6403 - val_accuracy: 0.2249\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.4866 - accuracy: 0.9240 - val_loss: 2.6590 - val_accuracy: 0.2011\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.5801 - accuracy: 0.8946 - val_loss: 2.7168 - val_accuracy: 0.1852\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.5820 - accuracy: 0.9184 - val_loss: 2.6232 - val_accuracy: 0.2011\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.6163 - accuracy: 0.9161 - val_loss: 2.6584 - val_accuracy: 0.2037\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.5587 - accuracy: 0.9320 - val_loss: 2.6601 - val_accuracy: 0.1878\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.6010 - accuracy: 0.9093 - val_loss: 2.6915 - val_accuracy: 0.1958\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.4904 - accuracy: 0.9444 - val_loss: 2.6392 - val_accuracy: 0.1878\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.3819 - accuracy: 0.9830 - val_loss: 2.6146 - val_accuracy: 0.2063\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.3026 - accuracy: 0.9875 - val_loss: 2.6009 - val_accuracy: 0.2090\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.2502 - accuracy: 0.9966 - val_loss: 2.5967 - val_accuracy: 0.2169\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.2285 - accuracy: 0.9955 - val_loss: 2.6192 - val_accuracy: 0.2222\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.2098 - accuracy: 0.9977 - val_loss: 2.6076 - val_accuracy: 0.2143\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.1958 - accuracy: 1.0000 - val_loss: 2.6481 - val_accuracy: 0.2143\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.1870 - accuracy: 1.0000 - val_loss: 2.6406 - val_accuracy: 0.2063\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.1782 - accuracy: 0.9989 - val_loss: 2.6383 - val_accuracy: 0.2169\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.1703 - accuracy: 1.0000 - val_loss: 2.6457 - val_accuracy: 0.2143\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.1666 - accuracy: 1.0000 - val_loss: 2.6513 - val_accuracy: 0.2222\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.1625 - accuracy: 1.0000 - val_loss: 2.6623 - val_accuracy: 0.2169\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.1568 - accuracy: 1.0000 - val_loss: 2.6433 - val_accuracy: 0.2222\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.1512 - accuracy: 1.0000 - val_loss: 2.6584 - val_accuracy: 0.2196\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.1453 - accuracy: 1.0000 - val_loss: 2.6743 - val_accuracy: 0.2063\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.1432 - accuracy: 0.9989 - val_loss: 2.6700 - val_accuracy: 0.2116\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.1388 - accuracy: 1.0000 - val_loss: 2.6741 - val_accuracy: 0.2196\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.1353 - accuracy: 1.0000 - val_loss: 2.6823 - val_accuracy: 0.2011\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.1314 - accuracy: 1.0000 - val_loss: 2.6723 - val_accuracy: 0.2063\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.1284 - accuracy: 1.0000 - val_loss: 2.6771 - val_accuracy: 0.2116\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.1253 - accuracy: 1.0000 - val_loss: 2.6698 - val_accuracy: 0.2143\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.1236 - accuracy: 1.0000 - val_loss: 2.6835 - val_accuracy: 0.2143\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.1204 - accuracy: 1.0000 - val_loss: 2.6903 - val_accuracy: 0.2063\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 2.6905 - val_accuracy: 0.2222\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.1162 - accuracy: 1.0000 - val_loss: 2.6970 - val_accuracy: 0.2037\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.1144 - accuracy: 1.0000 - val_loss: 2.6901 - val_accuracy: 0.2063\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.1114 - accuracy: 1.0000 - val_loss: 2.6994 - val_accuracy: 0.2090\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 2.7012 - val_accuracy: 0.2143\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 2.7151 - val_accuracy: 0.2063\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 2.7090 - val_accuracy: 0.2116\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 2.7138 - val_accuracy: 0.2196\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 2.7182 - val_accuracy: 0.2090\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 2.7191 - val_accuracy: 0.2169\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.0976 - accuracy: 1.0000 - val_loss: 2.7233 - val_accuracy: 0.2143\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 2.7293 - val_accuracy: 0.2090\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 2.7336 - val_accuracy: 0.2143\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 2.7327 - val_accuracy: 0.2143\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 2.7345 - val_accuracy: 0.2169\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 2.7398 - val_accuracy: 0.2143\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 2.7407 - val_accuracy: 0.2196\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 2.7494 - val_accuracy: 0.2169\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 2.7427 - val_accuracy: 0.2090\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 2.7564 - val_accuracy: 0.2196\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 2.7532 - val_accuracy: 0.2063\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 2.7435 - val_accuracy: 0.2222\n",
      "Epoch 157/200\n",
      "2/9 [=====>........................] - ETA: 1s - loss: 0.0732 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fd1b8c7fffc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=100, epochs=200, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
